{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42,  0.67,  0.75,  0.83,  0.92,  1.  ,  2.  ,  3.  ,  4.  ,\n",
       "        5.  ,  6.  ,  7.  ,  8.  ,  9.  , 10.  , 11.  , 12.  , 13.  ,\n",
       "       14.  , 14.5 , 15.  , 16.  , 17.  , 18.  , 19.  , 20.  , 20.5 ,\n",
       "       21.  , 22.  , 23.  , 23.5 , 24.  , 24.5 , 25.  , 26.  , 27.  ,\n",
       "       28.  , 28.5 , 29.  , 30.  , 30.5 , 31.  , 32.  , 32.5 , 33.  ,\n",
       "       34.  , 34.5 , 35.  , 36.  , 36.5 , 37.  , 38.  , 39.  , 40.  ,\n",
       "       40.5 , 41.  , 42.  , 43.  , 44.  , 45.  , 45.5 , 46.  , 47.  ,\n",
       "       48.  , 49.  , 50.  , 51.  , 52.  , 53.  , 54.  , 55.  , 55.5 ,\n",
       "       56.  , 57.  , 58.  , 59.  , 60.  , 61.  , 62.  , 63.  , 64.  ,\n",
       "       65.  , 66.  , 70.  , 70.5 , 71.  , 74.  , 80.  ,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan,   nan,   nan])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = np.unique(titanic_df['Age'])\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.42,\n",
       " 1: 0.67,\n",
       " 2: 0.75,\n",
       " 3: 0.83,\n",
       " 4: 0.92,\n",
       " 5: 1.0,\n",
       " 6: 2.0,\n",
       " 7: 3.0,\n",
       " 8: 4.0,\n",
       " 9: 5.0,\n",
       " 10: 6.0,\n",
       " 11: 7.0,\n",
       " 12: 8.0,\n",
       " 13: 9.0,\n",
       " 14: 10.0,\n",
       " 15: 11.0,\n",
       " 16: 12.0,\n",
       " 17: 13.0,\n",
       " 18: 14.0,\n",
       " 19: 14.5,\n",
       " 20: 15.0,\n",
       " 21: 16.0,\n",
       " 22: 17.0,\n",
       " 23: 18.0,\n",
       " 24: 19.0,\n",
       " 25: 20.0,\n",
       " 26: 20.5,\n",
       " 27: 21.0,\n",
       " 28: 22.0,\n",
       " 29: 23.0,\n",
       " 30: 23.5,\n",
       " 31: 24.0,\n",
       " 32: 24.5,\n",
       " 33: 25.0,\n",
       " 34: 26.0,\n",
       " 35: 27.0,\n",
       " 36: 28.0,\n",
       " 37: 28.5,\n",
       " 38: 29.0,\n",
       " 39: 30.0,\n",
       " 40: 30.5,\n",
       " 41: 31.0,\n",
       " 42: 32.0,\n",
       " 43: 32.5,\n",
       " 44: 33.0,\n",
       " 45: 34.0,\n",
       " 46: 34.5,\n",
       " 47: 35.0,\n",
       " 48: 36.0,\n",
       " 49: 36.5,\n",
       " 50: 37.0,\n",
       " 51: 38.0,\n",
       " 52: 39.0,\n",
       " 53: 40.0,\n",
       " 54: 40.5,\n",
       " 55: 41.0,\n",
       " 56: 42.0,\n",
       " 57: 43.0,\n",
       " 58: 44.0,\n",
       " 59: 45.0,\n",
       " 60: 45.5,\n",
       " 61: 46.0,\n",
       " 62: 47.0,\n",
       " 63: 48.0,\n",
       " 64: 49.0,\n",
       " 65: 50.0,\n",
       " 66: 51.0,\n",
       " 67: 52.0,\n",
       " 68: 53.0,\n",
       " 69: 54.0,\n",
       " 70: 55.0,\n",
       " 71: 55.5,\n",
       " 72: 56.0,\n",
       " 73: 57.0,\n",
       " 74: 58.0,\n",
       " 75: 59.0,\n",
       " 76: 60.0,\n",
       " 77: 61.0,\n",
       " 78: 62.0,\n",
       " 79: 63.0,\n",
       " 80: 64.0,\n",
       " 81: 65.0,\n",
       " 82: 66.0,\n",
       " 83: 70.0,\n",
       " 84: 70.5,\n",
       " 85: 71.0,\n",
       " 86: 74.0,\n",
       " 87: 80.0,\n",
       " 88: nan,\n",
       " 89: nan,\n",
       " 90: nan,\n",
       " 91: nan,\n",
       " 92: nan,\n",
       " 93: nan,\n",
       " 94: nan,\n",
       " 95: nan,\n",
       " 96: nan,\n",
       " 97: nan,\n",
       " 98: nan,\n",
       " 99: nan,\n",
       " 100: nan,\n",
       " 101: nan,\n",
       " 102: nan,\n",
       " 103: nan,\n",
       " 104: nan,\n",
       " 105: nan,\n",
       " 106: nan,\n",
       " 107: nan,\n",
       " 108: nan,\n",
       " 109: nan,\n",
       " 110: nan,\n",
       " 111: nan,\n",
       " 112: nan,\n",
       " 113: nan,\n",
       " 114: nan,\n",
       " 115: nan,\n",
       " 116: nan,\n",
       " 117: nan,\n",
       " 118: nan,\n",
       " 119: nan,\n",
       " 120: nan,\n",
       " 121: nan,\n",
       " 122: nan,\n",
       " 123: nan,\n",
       " 124: nan,\n",
       " 125: nan,\n",
       " 126: nan,\n",
       " 127: nan,\n",
       " 128: nan,\n",
       " 129: nan,\n",
       " 130: nan,\n",
       " 131: nan,\n",
       " 132: nan,\n",
       " 133: nan,\n",
       " 134: nan,\n",
       " 135: nan,\n",
       " 136: nan,\n",
       " 137: nan,\n",
       " 138: nan,\n",
       " 139: nan,\n",
       " 140: nan,\n",
       " 141: nan,\n",
       " 142: nan,\n",
       " 143: nan,\n",
       " 144: nan,\n",
       " 145: nan,\n",
       " 146: nan,\n",
       " 147: nan,\n",
       " 148: nan,\n",
       " 149: nan,\n",
       " 150: nan,\n",
       " 151: nan,\n",
       " 152: nan,\n",
       " 153: nan,\n",
       " 154: nan,\n",
       " 155: nan,\n",
       " 156: nan,\n",
       " 157: nan,\n",
       " 158: nan,\n",
       " 159: nan,\n",
       " 160: nan,\n",
       " 161: nan,\n",
       " 162: nan,\n",
       " 163: nan,\n",
       " 164: nan,\n",
       " 165: nan,\n",
       " 166: nan,\n",
       " 167: nan,\n",
       " 168: nan,\n",
       " 169: nan,\n",
       " 170: nan,\n",
       " 171: nan,\n",
       " 172: nan,\n",
       " 173: nan,\n",
       " 174: nan,\n",
       " 175: nan,\n",
       " 176: nan,\n",
       " 177: nan,\n",
       " 178: nan,\n",
       " 179: nan,\n",
       " 180: nan,\n",
       " 181: nan,\n",
       " 182: nan,\n",
       " 183: nan,\n",
       " 184: nan,\n",
       " 185: nan,\n",
       " 186: nan,\n",
       " 187: nan,\n",
       " 188: nan,\n",
       " 189: nan,\n",
       " 190: nan,\n",
       " 191: nan,\n",
       " 192: nan,\n",
       " 193: nan,\n",
       " 194: nan,\n",
       " 195: nan,\n",
       " 196: nan,\n",
       " 197: nan,\n",
       " 198: nan,\n",
       " 199: nan,\n",
       " 200: nan,\n",
       " 201: nan,\n",
       " 202: nan,\n",
       " 203: nan,\n",
       " 204: nan,\n",
       " 205: nan,\n",
       " 206: nan,\n",
       " 207: nan,\n",
       " 208: nan,\n",
       " 209: nan,\n",
       " 210: nan,\n",
       " 211: nan,\n",
       " 212: nan,\n",
       " 213: nan,\n",
       " 214: nan,\n",
       " 215: nan,\n",
       " 216: nan,\n",
       " 217: nan,\n",
       " 218: nan,\n",
       " 219: nan,\n",
       " 220: nan,\n",
       " 221: nan,\n",
       " 222: nan,\n",
       " 223: nan,\n",
       " 224: nan,\n",
       " 225: nan,\n",
       " 226: nan,\n",
       " 227: nan,\n",
       " 228: nan,\n",
       " 229: nan,\n",
       " 230: nan,\n",
       " 231: nan,\n",
       " 232: nan,\n",
       " 233: nan,\n",
       " 234: nan,\n",
       " 235: nan,\n",
       " 236: nan,\n",
       " 237: nan,\n",
       " 238: nan,\n",
       " 239: nan,\n",
       " 240: nan,\n",
       " 241: nan,\n",
       " 242: nan,\n",
       " 243: nan,\n",
       " 244: nan,\n",
       " 245: nan,\n",
       " 246: nan,\n",
       " 247: nan,\n",
       " 248: nan,\n",
       " 249: nan,\n",
       " 250: nan,\n",
       " 251: nan,\n",
       " 252: nan,\n",
       " 253: nan,\n",
       " 254: nan,\n",
       " 255: nan,\n",
       " 256: nan,\n",
       " 257: nan,\n",
       " 258: nan,\n",
       " 259: nan,\n",
       " 260: nan,\n",
       " 261: nan,\n",
       " 262: nan,\n",
       " 263: nan,\n",
       " 264: nan}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "gle = LabelEncoder()\n",
    "age_labels = gle.fit_transform(titanic_df['Age'])\n",
    "age_mappings = {index: label for index, label in \n",
    "                  enumerate(gle.classes_)}\n",
    "age_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73010796, -0.78927234,  0.82737724, -0.53037664,  0.43279337,\n",
       "        -0.47367361, -0.50244517],\n",
       "       [-1.72622007,  1.2669898 , -1.56610693,  0.57183099,  0.43279337,\n",
       "        -0.47367361,  0.78684529]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(titanic_df._get_numeric_data())[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 0.27117366, 0.125     ,\n",
       "        0.        , 0.01415106],\n",
       "       [0.0011236 , 1.        , 0.        , 0.4722292 , 0.125     ,\n",
       "        0.        , 0.13913574]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit_transform(titanic_df._get_numeric_data())[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
